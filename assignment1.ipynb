{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samkaj/appliedml-1/blob/main/assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggLECFbWtkYM"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "By Group 5: Samuel Kajava and Torbjörn Livén\n",
        "\n",
        "[Instructions](https://www.cse.chalmers.se/~richajo/dit866/assignments/a1/assignment1.html) here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9sAB53kuUgI",
        "outputId": "8329e166-658f-4035-b3aa-00e7bb69351b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-01-15 20:42:13--  https://www.cse.chalmers.se/~richajo/dit866/data/CTG.csv\n",
            "Resolving www.cse.chalmers.se (www.cse.chalmers.se)... 129.16.221.33\n",
            "Connecting to www.cse.chalmers.se (www.cse.chalmers.se)|129.16.221.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 307385 (300K) [text/plain]\n",
            "Saving to: ‘CTG.csv.1’\n",
            "\n",
            "CTG.csv.1           100%[===================>] 300,18K   474KB/s    in 0,6s    \n",
            "\n",
            "2024-01-15 20:42:14 (474 KB/s) - ‘CTG.csv.1’ saved [307385/307385]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Fetch the CTG data set.\n",
        "!wget https://www.cse.chalmers.se/~richajo/dit866/data/CTG.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UHxGFV10txRs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the CSV file.\n",
        "data = pd.read_csv('CTG.csv', skiprows=1)\n",
        "\n",
        "# Select the relevant numerical columns.\n",
        "selected_cols = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV',\n",
        "                 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean',\n",
        "                 'Median', 'Variance', 'Tendency', 'NSP']\n",
        "data = data[selected_cols].dropna()\n",
        "\n",
        "# Shuffle the dataset.\n",
        "data_shuffled = data.sample(frac=1.0, random_state=0)\n",
        "\n",
        "# Split into input part X and output part Y.\n",
        "X = data_shuffled.drop('NSP', axis=1)\n",
        "\n",
        "# Map the diagnosis code to a human-readable label.\n",
        "def to_label(y):\n",
        "    return [None, 'normal', 'suspect', 'pathologic'][(int(y))]\n",
        "\n",
        "Y = data_shuffled['NSP'].apply(to_label)\n",
        "\n",
        "# Partition the data into training and test sets.\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "MmSVkGygupV3",
        "outputId": "90c99e15-d729-4269-cfac-7986e77e5e61"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LB</th>\n",
              "      <th>AC</th>\n",
              "      <th>FM</th>\n",
              "      <th>UC</th>\n",
              "      <th>DL</th>\n",
              "      <th>DS</th>\n",
              "      <th>DP</th>\n",
              "      <th>ASTV</th>\n",
              "      <th>MSTV</th>\n",
              "      <th>ALTV</th>\n",
              "      <th>...</th>\n",
              "      <th>Width</th>\n",
              "      <th>Min</th>\n",
              "      <th>Max</th>\n",
              "      <th>Nmax</th>\n",
              "      <th>Nzeros</th>\n",
              "      <th>Mode</th>\n",
              "      <th>Mean</th>\n",
              "      <th>Median</th>\n",
              "      <th>Variance</th>\n",
              "      <th>Tendency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>658</th>\n",
              "      <td>130.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>12.0</td>\n",
              "      <td>...</td>\n",
              "      <td>35.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1734</th>\n",
              "      <td>134.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>109.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>189.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1226</th>\n",
              "      <td>125.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>31.0</td>\n",
              "      <td>...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1808</th>\n",
              "      <td>143.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>27.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>825</th>\n",
              "      <td>152.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>59.0</td>\n",
              "      <td>...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         LB   AC   FM   UC   DL   DS   DP  ASTV  MSTV  ALTV  ...  Width  \\\n",
              "658   130.0  1.0  0.0  3.0  0.0  0.0  0.0  24.0   1.2  12.0  ...   35.0   \n",
              "1734  134.0  9.0  1.0  8.0  5.0  0.0  0.0  59.0   1.2   0.0  ...  109.0   \n",
              "1226  125.0  1.0  0.0  4.0  0.0  0.0  0.0  43.0   0.7  31.0  ...   21.0   \n",
              "1808  143.0  0.0  0.0  1.0  0.0  0.0  0.0  69.0   0.3   6.0  ...   27.0   \n",
              "825   152.0  0.0  0.0  4.0  0.0  0.0  0.0  62.0   0.4  59.0  ...   25.0   \n",
              "\n",
              "        Min    Max  Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  \n",
              "658   120.0  155.0   1.0     0.0  134.0  133.0   135.0       1.0       0.0  \n",
              "1734   80.0  189.0   6.0     0.0  150.0  146.0   150.0      33.0       0.0  \n",
              "1226  120.0  141.0   0.0     0.0  131.0  130.0   132.0       1.0       0.0  \n",
              "1808  132.0  159.0   1.0     0.0  145.0  144.0   146.0       1.0       0.0  \n",
              "825   136.0  161.0   0.0     0.0  159.0  156.0   158.0       1.0       1.0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Take a peak at the data.\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWFCIyBevAkH"
      },
      "source": [
        "## Step 2. Training the baseline classifier\n",
        "\n",
        "We begin by using a dummy classifier as a baseline for our upcomping implementation. A higher aggregated result means that the accuracy is higher, so we want to find a classifier with a good aggregated result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "# Create dummy classifier.\n",
        "clf = DummyClassifier(strategy='most_frequent')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform cross validation.\n",
        "dummy_cross_val = cross_val_score(clf, Xtrain, Ytrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we have cross validated the scores, we now aggregate the results to make it comparable to other classifiers. We use the mean to find a good representation of the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7805882352941176"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Returns the aggregation of an array of numbers.\n",
        "def aggregate(arr: np.ndarray):\n",
        "  # return the mean of the array\n",
        "  return np.mean(arr)\n",
        "\n",
        "dummy_aggr = aggregate(dummy_cross_val)\n",
        "dummy_aggr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3. Trying out different classifiers\n",
        "\n",
        "In this step, we use a number of classifiers and compare the aggregated results using the `aggregate()` function defined above. We choose to scale the data to help the linear classifiers converge [[1]](https://scikit-learn.org/stable/modules/preprocessing.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale the data.\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(Xtrain)\n",
        "Xtrain = scaler.transform(Xtrain)\n",
        "Xtest = scaler.transform(Xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline:\n",
            "---------\n",
            "Dummy: 0.7805882352941176\n",
            "\n",
            "Tree-based:\n",
            "-----------\n",
            "Decision tree: 0.9229411764705882\n",
            "Random forest: 0.9364705882352942\n",
            "Gradient boost: 0.9476470588235294\n",
            "\n",
            "Linear:\n",
            "-------\n",
            "Perceptron: 0.8729411764705883\n",
            "Logistic regression: 0.891764705882353\n",
            "Linear SVC: 0.8905882352941177\n",
            "\n",
            "Neural net:\n",
            "-----------\n"
          ]
        }
      ],
      "source": [
        "import sklearn.tree as tree\n",
        "import sklearn.ensemble as ensemble\n",
        "import sklearn.linear_model as linear\n",
        "import sklearn.svm as svm \n",
        "import sklearn.neural_network as nn\n",
        "\n",
        "# Run cross validation on decision tree, random forest, gradient boosting, perceptron, logistic regression, linear SVC and MLP.\n",
        "tree_clf = tree.DecisionTreeClassifier()\n",
        "tree_cross_val = cross_val_score(tree_clf, Xtrain, Ytrain)\n",
        "\n",
        "forest_clf = ensemble.RandomForestClassifier()\n",
        "forest_cross_val = cross_val_score(forest_clf, Xtrain, Ytrain)\n",
        "\n",
        "gb_clf = ensemble.GradientBoostingClassifier(max_depth=10)\n",
        "gb_cross_val = cross_val_score(gb_clf, Xtrain, Ytrain)\n",
        "\n",
        "perceptron_clf = linear.Perceptron()\n",
        "perceptron_cross_val = cross_val_score(perceptron_clf, Xtrain, Ytrain)\n",
        "\n",
        "logreg_clf = linear.LogisticRegression()\n",
        "logreg_cross_val = cross_val_score(logreg_clf, Xtrain, Ytrain)\n",
        "\n",
        "linsvc_clf = svm.LinearSVC(dual=False)\n",
        "linsvc_cross_val = cross_val_score(linsvc_clf, Xtrain, Ytrain)\n",
        "\n",
        "mlp_clf = nn.MLPClassifier(max_iter=3000, hidden_layer_sizes=(100,100), solver='adam')\n",
        "mlp_cross_val = cross_val_score(mlp_clf, Xtrain, Ytrain)\n",
        "\n",
        "# Aggregate the results.\n",
        "tree_aggr = aggregate(tree_cross_val)\n",
        "forest_aggr = aggregate(forest_cross_val)\n",
        "gb_aggr = aggregate(gb_cross_val)\n",
        "perceptron_aggr = aggregate(perceptron_cross_val)\n",
        "logreg_aggr = aggregate(logreg_cross_val)\n",
        "linsvc_aggr = aggregate(linsvc_cross_val)\n",
        "mlp_aggr = aggregate(mlp_cross_val)\n",
        "\n",
        "# Print the results.\n",
        "print('Baseline:\\n---------')\n",
        "print('Dummy:', dummy_aggr)\n",
        "\n",
        "print('\\nTree-based:\\n-----------')\n",
        "print('Decision tree:', tree_aggr)\n",
        "print('Random forest:', forest_aggr)\n",
        "print('Gradient boost:', gb_aggr)\n",
        "\n",
        "print('\\nLinear:\\n-------')\n",
        "print('Perceptron:', perceptron_aggr)\n",
        "print('Logistic regression:', logreg_aggr)\n",
        "print('Linear SVC:', linsvc_aggr)\n",
        "\n",
        "print('\\nNeural net:\\n-----------')\n",
        "print('MLP:', mlp_aggr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Choosing the best classifier\n",
        "\n",
        "With the cross validation results finished and aggregated, we choose the best performing one based on their scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model: Gradient boost\n",
            "Accuracy: 0.9272300469483568\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Candidate models and their aggregation results.\n",
        "candidates = {\n",
        "    'Decision tree': (tree_clf, tree_aggr),\n",
        "    'Random forest': (forest_clf, forest_aggr),\n",
        "    'Gradient boost': (gb_clf, gb_aggr),\n",
        "    'Perceptron': (perceptron_clf, perceptron_aggr),\n",
        "    'Logistic regression': (logreg_clf, logreg_aggr),\n",
        "    'Linear SVC': (linsvc_clf, linsvc_aggr),\n",
        "    'MLP': (mlp_clf, mlp_aggr)\n",
        "}\n",
        "\n",
        "# Find the best model.\n",
        "best = None\n",
        "for candidate in candidates:\n",
        "  if best is None or candidates[candidate][1] > candidates[best][1]:\n",
        "    best = candidate\n",
        "\n",
        "print('Best model:', best)\n",
        "best_clf = candidates[best][0]\n",
        "best_clf.fit(Xtrain, Ytrain)\n",
        "Yguess = best_clf.predict(Xtest)\n",
        "print('Accuracy:', accuracy_score(Ytest, Yguess))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
